{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from types import SimpleNamespace\n",
    "import scipy\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets data location\n",
    "experiment = 'E300'#'E338'\n",
    "runname = '12427'#'12691'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define XTCAV calibration\n",
    "krf = 239.26\n",
    "cal = 1167 # um/deg  http://physics-elog.slac.stanford.edu/facetelog/show.jsp?dir=/2025/11/13.03&pos=2025-$\n",
    "streakFromGUI = cal*krf*180/np.pi*1e-6#um/um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the main beam energy\n",
    "mainbeamE_eV = 10e9\n",
    "# Sets the dnom value for CHER\n",
    "dnom = 59.8e-3\n",
    "\n",
    "# Sets the calibration value for SYAG in eV/m\n",
    "SYAG_cal = 64.4e9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads dataset\n",
    "dataloc = '../data/raw/' + experiment + '/' + experiment + '_' + runname + '/' + experiment + '_'  +runname + '.mat'\n",
    "mat = loadmat(dataloc,struct_as_record=False, squeeze_me=True)\n",
    "data_struct = mat['data_struct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts number of steps\n",
    "stepsAll = data_struct.params.stepsAll\n",
    "if stepsAll is None or len(np.atleast_1d(stepsAll)) == 0:\n",
    "    stepsAll = 1\n",
    "\n",
    "# calculate xt calibration factor\n",
    "xtcalibrationfactor = data_struct.metadata.DTOTR2.RESOLUTION*1e-6/streakFromGUI/3e8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab XTCAV images on DTOTR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTOTR2data = None\n",
    "\n",
    "for a in range(len(stepsAll)):\n",
    "    raw_path = data_struct.images.DTOTR2.loc[a]\n",
    "    match = re.search(rf'({experiment}_\\d+/images/DTOTR2/DTOTR2_data_step\\d+\\.h5)', raw_path)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Path format invalid or not matched: {raw_path}\")\n",
    "\n",
    "    DTOTR2datalocation = f'../data/raw/{experiment}/' + match.group(0)\n",
    "\n",
    "    with h5py.File(DTOTR2datalocation, 'r') as f:\n",
    "        data_raw = f['entry']['data']['data'][:].astype(np.float64)  # shape: (N, H, W)\n",
    "    # Transpose to shape: (H, W, N)\n",
    "    data_transposed = np.transpose(data_raw, (2, 1, 0))\n",
    "    \n",
    "    xtcavImages = data_transposed - data_struct.backgrounds.DTOTR2[:,:,np.newaxis].astype(np.float64)\n",
    "    if DTOTR2data is None:\n",
    "        DTOTR2data = data_transposed\n",
    "    else:\n",
    "        # Append along the third axis\n",
    "        DTOTR2data = np.concatenate((DTOTR2data, data_transposed), axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeps only the data with a common index\n",
    "DTOTR2commonind = data_struct.images.DTOTR2.common_index -1 \n",
    "DTOTR2data_com = DTOTR2data[:, :, DTOTR2commonind]\n",
    "\n",
    "nshots = DTOTR2data_com.shape[2]\n",
    "print(DTOTR2data_com.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtcavImages = DTOTR2data_com - data_struct.backgrounds.DTOTR2[:,:,np.newaxis].astype(np.float64)\n",
    "print(xtcavImages.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the XTCAV phase on each shot (important if toggler is on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matstruct_to_dict(obj):\n",
    "    \"\"\"\n",
    "    Recursively convert MATLAB structs (loaded via scipy.io.loadmat) to Python dictionaries.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, scipy.io.matlab.mio5_params.mat_struct):\n",
    "        result = {}\n",
    "        for fieldname in obj._fieldnames:\n",
    "            result[fieldname] = matstruct_to_dict(getattr(obj, fieldname))\n",
    "        return result\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        if obj.dtype == 'object':\n",
    "            return [matstruct_to_dict(o) for o in obj]\n",
    "        else:\n",
    "            return obj\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDAQBSAScalars(data_struct):\n",
    "    data_struct = matstruct_to_dict(data_struct)\n",
    "    dataScalars = data_struct['scalars']\n",
    "    idx = dataScalars['common_index'].astype(int).flatten()\n",
    "\n",
    "    fNames = list(dataScalars.keys())\n",
    "    isBSA = [name for name in fNames if name.startswith('BSA_List_')]\n",
    "\n",
    "    bsaScalarData = []\n",
    "    bsaVarPVs = []\n",
    "\n",
    "    for bsaName in isBSA:\n",
    "        bsaList = dataScalars[bsaName]\n",
    "        varNames = list(bsaList.keys())\n",
    "        bsaListData = []\n",
    "\n",
    "        for varName in varNames:\n",
    "            varData = np.array(bsaList[varName]).squeeze()\n",
    "            if varData.size == 0:\n",
    "                continue\n",
    "            varData = varData[idx]  # apply common index\n",
    "            varData = np.nan_to_num(varData)  # replace NaN with 0\n",
    "            bsaListData.append(varData)\n",
    "\n",
    "        # Add to output arrays\n",
    "        bsaVarPVs.extend([vn for vn in varNames if bsaList[vn].size != 0])\n",
    "        if bsaListData:\n",
    "            bsaScalarData.extend(bsaListData)\n",
    "\n",
    "    bsaScalarData = np.array(bsaScalarData)\n",
    "    return bsaScalarData, bsaVarPVs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsaScalarData, bsaVars = extractDAQBSAScalars(data_struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ampl_idx = next(i for i, var in enumerate(bsaVars) if 'TCAV_LI20_2400_A' in var)\n",
    "xtcavAmpl = bsaScalarData[ampl_idx, :]\n",
    "\n",
    "phase_idx = next(i for i, var in enumerate(bsaVars) if 'TCAV_LI20_2400_P' in var)\n",
    "xtcavPhase = bsaScalarData[phase_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtcavOffShots = xtcavAmpl<0.1\n",
    "xtcavPhase[xtcavOffShots] = 0 #Set this for ease of plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(xtcavAmpl, label='Amplitude', color='b')\n",
    "ax1.set_ylabel('XTCAV Ampl [MV]', color='b')\n",
    "ax1.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(xtcavPhase, label='Phase', color='r')\n",
    "ax2.set_ylabel('XTCAV Phase [deg]', color='r')\n",
    "ax2.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "plt.title('XTCAV Amplitude and Phase')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot sample images of the beam with tcav at +90 deg, 0 and -90 deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cropProfmonImg(img, xrange, yrange, plot_flag=False):\n",
    "    \"\"\"\n",
    "    Crop a 2D image around the peak of horizontal and vertical projections,\n",
    "    returning a region of shape (2*yrange, 2*xrange), with padding if needed.\n",
    "\n",
    "    Args:\n",
    "        img (2D np.ndarray): Input image.\n",
    "        xrange (int): Half-width in x-direction.\n",
    "        yrange (int): Half-height in y-direction.\n",
    "        plot_flag (bool): If True, show plots.\n",
    "\n",
    "    Returns:\n",
    "        cropped_img (2D np.ndarray): Cropped image (always 2*yrange by 2*xrange).\n",
    "        error_flag (int): 0 if successful, 1 if fallback used.\n",
    "    \"\"\"\n",
    "    img = img.astype(float)\n",
    "    img_h, img_w = img.shape\n",
    "\n",
    "    # Use max projections to find \"COM\"\n",
    "    x_com = int(np.argmax(np.sum(img, axis=0)))\n",
    "    y_com = int(np.argmax(np.sum(img, axis=1)))\n",
    "\n",
    "    # Desired window size\n",
    "    x_start = x_com - xrange\n",
    "    x_end   = x_com + xrange\n",
    "    y_start = y_com - yrange\n",
    "    y_end   = y_com + yrange\n",
    "\n",
    "    # Compute required padding if indices go out of bounds\n",
    "    pad_left   = max(0, -x_start)\n",
    "    pad_right  = max(0, x_end - img_w)\n",
    "    pad_top    = max(0, -y_start)\n",
    "    pad_bottom = max(0, y_end - img_h)\n",
    "\n",
    "    # Pad image as needed\n",
    "    if any([pad_left, pad_right, pad_top, pad_bottom]):\n",
    "        img = np.pad(img, \n",
    "                     ((pad_top, pad_bottom), (pad_left, pad_right)), \n",
    "                     mode='constant', constant_values=0)\n",
    "        error_flag = 1  # Fallback was needed\n",
    "    else:\n",
    "        error_flag = 0\n",
    "\n",
    "    # Recalculate indices after padding\n",
    "    x_start += pad_left\n",
    "    x_end   += pad_left\n",
    "    y_start += pad_top\n",
    "    y_end   += pad_top\n",
    "\n",
    "    # Crop\n",
    "    cropped_img = img[y_start:y_end, x_start:x_end]\n",
    "\n",
    "    # Sanity check\n",
    "    if cropped_img.shape != (2*yrange, 2*xrange):\n",
    "        warnings.warn(f\"Cropped image shape mismatch: got {cropped_img.shape}\")\n",
    "        error_flag = 1\n",
    "\n",
    "    if plot_flag:\n",
    "        fig, axs = plt.subplots(2, 1, figsize=(8, 6))\n",
    "        axs[0].imshow(img, cmap='viridis', aspect='auto')\n",
    "        axs[0].set_title(\"Original / Padded Image\")\n",
    "        axs[1].imshow(cropped_img, cmap='viridis', aspect='auto')\n",
    "        axs[1].set_title(\"Cropped Image\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return cropped_img, error_flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the first shot where tcav is at -90, 0 and +90 deg\n",
    "near_minus_90_idx = np.where((xtcavPhase >= -90.55) & (xtcavPhase <= -89.55))[0][1]\n",
    "near_plus_90_idx = np.where((xtcavPhase >= 89.55) & (xtcavPhase <= 90.55))[0][1]\n",
    "zero_idx = np.where(xtcavPhase == 0)[0][1]\n",
    "\n",
    "sample_image_indices = [near_minus_90_idx, zero_idx, near_plus_90_idx]\n",
    "plot_titles = ['Tcav phase -90 deg', '0 deg', '+90 deg']\n",
    "\n",
    "\n",
    "# Define the x and yrange for cropping the image; Need to automate this\n",
    "# figure;imagesc(sampleImage)\n",
    "\n",
    "xrange = 100\n",
    "yrange = xrange\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "fig.suptitle(f'TCAV images before centroid correction DAQ {experiment} - {runname}', fontsize=14)\n",
    "\n",
    "for i, idx in enumerate(sample_image_indices):\n",
    "    if idx is None:\n",
    "        continue\n",
    "\n",
    "    sample_image = xtcavImages[:, :, idx]\n",
    "    sample_image_cropped, _ = cropProfmonImg(sample_image, xrange, yrange, plot_flag=False)\n",
    "    horz_proj = np.sum(sample_image_cropped, axis=0)\n",
    "\n",
    "    axs[0, i].imshow(sample_image_cropped, cmap='jet', aspect='auto')\n",
    "    axs[0, i].set_title(plot_titles[i])\n",
    "\n",
    "    axs[1, i].plot(horz_proj)\n",
    "    axs[1, i].set_title(\"Horizontal Projection\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate centroid correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import median_filter, gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_tcav_off = xtcavImages[:, :, sample_image_indices[1]]\n",
    "sample_image_tcav_off, _ = cropProfmonImg(sample_image_tcav_off, xrange, yrange, plot_flag=False)\n",
    "\n",
    "img = median_filter(sample_image_tcav_off, size=3)\n",
    "sigma = 5\n",
    "processed_image = gaussian_filter(img, sigma=sigma)\n",
    "print(sample_image_tcav_off.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(processed_image, cmap='jet', aspect='auto')\n",
    "plt.title(\"Processed Image (Gaussian Filtered)\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(sample_image_tcav_off, cmap='jet', aspect='auto')\n",
    "plt.title(\"Original Cropped Image (TCAV Off)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_centroids_and_com(image, nrows, return_com=True):\n",
    "    \"\"\"\n",
    "    Segments the image row-wise and computes the center of mass for each row.\n",
    "\n",
    "    Parameters:\n",
    "    - image: 2D numpy array (cropped and processed XTCAV image)\n",
    "    - nrows: int, number of rows (typically image.shape[0])\n",
    "    - return_com: if True, returns center of mass positions; else returns only row indices\n",
    "\n",
    "    Returns:\n",
    "    - centroid_indices: numpy array of row indices (0 to nrows-1)\n",
    "    - centers_of_mass: numpy array of COM along the horizontal axis for each row\n",
    "    \"\"\"\n",
    "\n",
    "    height, width = image.shape\n",
    "    centroid_indices = np.arange(nrows)\n",
    "    centers_of_mass = np.zeros(nrows)\n",
    "\n",
    "    for i in range(nrows):\n",
    "        row = image[i, :]\n",
    "        total_mass = np.sum(row)\n",
    "        if total_mass > 0:\n",
    "            x_coords = np.arange(width)\n",
    "            com = np.sum(row * x_coords) / total_mass\n",
    "        else:\n",
    "            com = np.nan\n",
    "        centers_of_mass[i] = com\n",
    "\n",
    "    if return_com:\n",
    "        return centroid_indices, centers_of_mass\n",
    "    else:\n",
    "        return centroid_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply centroid correction to images and replot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nrows = np.array(sample_image_tcav_off).shape[0]\n",
    "[centroidIndices, centers_of_mass] = segment_centroids_and_com(processed_image, Nrows,1)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "fig.suptitle(f'TCAV images after centroid correction DAQ {experiment} - {runname}', fontsize=14)\n",
    "\n",
    "for i, idx in enumerate(sample_image_indices):\n",
    "    if idx is None:\n",
    "        continue\n",
    "\n",
    "    sample_image = xtcavImages[:, :, idx]\n",
    "    sample_image_cropped, _ = cropProfmonImg(sample_image, xrange, yrange, plot_flag=False)\n",
    "\n",
    "\n",
    "    centroid_corrections = np.round((centers_of_mass/np.abs(centers_of_mass))*np.abs(centers_of_mass) - centers_of_mass.shape[0] / 2)\n",
    "    # Convert to integer type (e.g., int32 or int64)\n",
    "    # This is the crucial step to fix the error:\n",
    "    centroid_corrections = centroid_corrections.astype(int) \n",
    "    centroid_corrections[np.isnan(centroid_corrections)] = 0\n",
    "\n",
    "    # Apply row-wise shift based on centroid correction\n",
    "    sample_image_shifted = np.empty_like(sample_image_cropped)\n",
    "    for row in range(sample_image_cropped.shape[0]):\n",
    "        shift = -centroid_corrections[row]\n",
    "        sample_image_shifted[row] = np.roll(sample_image_cropped[row], shift)\n",
    "\n",
    "    horz_proj = np.sum(sample_image_shifted, axis=0)\n",
    "\n",
    "    axs[0, i].imshow(sample_image_shifted, cmap='jet', aspect='auto')\n",
    "    axs[0, i].set_title(plot_titles[i])\n",
    "\n",
    "    axs[1, i].plot(horz_proj)\n",
    "    axs[1, i].set_title(\"Horizontal Projection\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the current profile normalizing the integral to the charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isChargePV = [bool(re.search(r'TORO_LI20_2452_TMIT', pv)) for pv in bsaVars]\n",
    "pvidx = [i for i, val in enumerate(isChargePV) if val]\n",
    "charge = bsaScalarData[pvidx, :] * 1.6e-19  # in C \n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "fig.suptitle(f'TCAV images with current profile after centroid correction')\n",
    "\n",
    "for i, (ij, idx) in enumerate([(i, idx) for i, idx in enumerate(sample_image_indices) if i != 1]):\n",
    "    sample_image = xtcavImages[:, :, idx]\n",
    "    sample_image_cropped, _ = cropProfmonImg(sample_image, xrange, yrange, plot_flag=False)\n",
    "\n",
    "    # Centroid correction\n",
    "    centroid_corrections = np.round((centers_of_mass / np.abs(centers_of_mass)) * np.abs(centers_of_mass) - centers_of_mass.shape[0] / 2)\n",
    "    centroid_corrections[np.isnan(centroid_corrections)] = 0\n",
    "\n",
    "    sample_image_shifted = np.empty_like(sample_image_cropped)\n",
    "    for row in range(sample_image_cropped.shape[0]):\n",
    "        shift = -int(centroid_corrections[row])\n",
    "        sample_image_shifted[row] = np.roll(sample_image_cropped[row], shift)\n",
    "\n",
    "    # Current profile\n",
    "    streakedProfile = np.sum(sample_image_shifted, axis=0)\n",
    "    tvar = np.arange(1, len(streakedProfile) + 1) * xtcalibrationfactor\n",
    "    tvar -= np.median(tvar)\n",
    "    prefactor = charge[0, idx] / np.trapz(streakedProfile, tvar)\n",
    "    currentProfile = streakedProfile * prefactor\n",
    "\n",
    "    # Plot image\n",
    "    axs[0, i].imshow(sample_image_shifted, cmap='jet', aspect='auto',\n",
    "                     extent=[tvar[0]*1e15, tvar[-1]*1e15, 1, sample_image_shifted.shape[0]])\n",
    "    axs[0, i].set_ylabel('y [pix]')\n",
    "    axs[0, i].set_title(plot_titles[ij])\n",
    "\n",
    "    # Plot projection\n",
    "    axs[1, i].plot(tvar * 1e15, currentProfile * 1e-3)\n",
    "    axs[1, i].set_xlabel('Time [fs]')\n",
    "    axs[1, i].set_ylabel('Current [kA]')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop thru all +90 and -90 deg shots and calculate the current profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note here i'm assuming the centroid correction can be taken from a single \n",
    "#    tcav off image. A better treatment would find the nearest tcav off image\n",
    "#   in the dataset and use that to apply the centroid correction on each shot\n",
    "\n",
    "minus_90_idx = np.where((xtcavPhase >= -91) & (xtcavPhase <= -89))[0]\n",
    "plus_90_idx = np.where((xtcavPhase >= 89) & (xtcavPhase <= 91))[0]\n",
    "\n",
    "currentProfile_minus_90 = []\n",
    "currentProfile_plus_90 = []\n",
    "\n",
    "# Process -90 degree shots\n",
    "for ij in range(len(minus_90_idx)):\n",
    "    idx = minus_90_idx[ij]\n",
    "    sample_image = xtcavImages[:, :, idx]\n",
    "    sample_image_cropped, _ = cropProfmonImg(sample_image, xrange, yrange, plot_flag=False)\n",
    "\n",
    "    centroid_corrections = np.round((centers_of_mass / np.abs(centers_of_mass)) * np.abs(centers_of_mass) - centers_of_mass.shape[0] / 2)\n",
    "    # Convert to integer type (e.g., int32 or int64)\n",
    "    centroid_corrections = centroid_corrections.astype(int)\n",
    "    centroid_corrections[np.isnan(centroid_corrections)] = 0\n",
    "\n",
    "    # Apply row-wise shift based on centroid correction\n",
    "    sample_image_shifted = np.empty_like(sample_image_cropped)\n",
    "    \n",
    "    for row in range(sample_image_cropped.shape[0]):\n",
    "        shift = -centroid_corrections[row]\n",
    "        sample_image_shifted[row] = np.roll(sample_image_cropped[row], shift)\n",
    "\n",
    "    # Calculate the current profile from the streaked projection\n",
    "    streakedProfile = np.sum(sample_image_cropped, axis=0)\n",
    "\n",
    "    tvar = np.arange(1, len(streakedProfile) + 1) * xtcalibrationfactor\n",
    "    tvar = tvar - np.median(tvar)  # Center around zero\n",
    "\n",
    "    prefactor = charge[0, idx] / np.trapz(streakedProfile, tvar)\n",
    "\n",
    "    currentProfile = 1e-3 * streakedProfile * prefactor  # Convert to kA\n",
    "    currentProfile_minus_90.append(currentProfile)\n",
    "\n",
    "# Process +90 degree shots\n",
    "for ij in range(len(plus_90_idx)):\n",
    "    idx = plus_90_idx[ij]\n",
    "    sample_image = xtcavImages[:, :, idx]\n",
    "    sample_image_cropped, _ = cropProfmonImg(sample_image, xrange, yrange, plot_flag=False)\n",
    "\n",
    "    centroid_corrections = np.round((centers_of_mass / np.abs(centers_of_mass)) * np.abs(centers_of_mass) - centers_of_mass.shape[0] / 2)\n",
    "    centroid_corrections = centroid_corrections.astype(int)\n",
    "\n",
    "    centroid_corrections[np.isnan(centroid_corrections)] = 0\n",
    "\n",
    "    # Apply row-wise shift based on centroid correction\n",
    "    sample_image_shifted = np.empty_like(sample_image_cropped)\n",
    "    for row in range(sample_image_cropped.shape[0]):\n",
    "        shift = -centroid_corrections[row]\n",
    "        sample_image_shifted[row] = np.roll(sample_image_cropped[row], shift)\n",
    "\n",
    "    # Calculate the current profile from the streaked projection\n",
    "    streakedProfile = np.sum(sample_image_cropped, axis=0)\n",
    "\n",
    "    tvar = np.arange(1, len(streakedProfile) + 1) * xtcalibrationfactor\n",
    "    tvar = tvar - np.median(tvar)  # Center around zero\n",
    "\n",
    "    prefactor = charge[0, idx] / np.trapz(streakedProfile, tvar)\n",
    "\n",
    "    currentProfile = 1e-3 * streakedProfile * prefactor  # Convert to kA\n",
    "    currentProfile_plus_90.append(currentProfile)\n",
    "\n",
    "# Convert lists to arrays for plotting\n",
    "currentProfile_minus_90 = np.array(currentProfile_minus_90)\n",
    "currentProfile_plus_90 = np.array(currentProfile_plus_90)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Subplot for -90°\n",
    "plt.subplot(2, 1, 1)\n",
    "extent_x = tvar * 3e8 * 1e6  # Convert to microns\n",
    "plt.imshow(currentProfile_minus_90, aspect='auto', cmap='jet', vmin=0, vmax=15, extent=[extent_x[0], extent_x[-1], minus_90_idx[-1], minus_90_idx[0]])\n",
    "plt.xlabel('z [μm]')\n",
    "plt.ylabel('Shot Number')\n",
    "plt.title(plot_titles[0])\n",
    "plt.colorbar(label='I [kA]')\n",
    "\n",
    "# Subplot for +90°\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(currentProfile_plus_90, aspect='auto', cmap='jet', vmin=0, vmax=15,extent=[extent_x[0], extent_x[-1], plus_90_idx[-1], plus_90_idx[0]])\n",
    "plt.xlabel('z [μm]')\n",
    "plt.ylabel('Shot Number')\n",
    "plt.title(plot_titles[2])\n",
    "plt.colorbar(label='I [kA]')\n",
    "\n",
    "plt.suptitle(f\"TCAV current DAQ {experiment} - {runname}\")\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the drive-witness separation and compare with BLEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ispv = [bool(re.search(r'BLEN_LI14_888_BRAW', pv)) for pv in bsaVars]\n",
    "pvidx = [i for i, val in enumerate(ispv) if val]\n",
    "bc14BLEN = bsaScalarData[pvidx,:]\n",
    "separationCutoff = 0.05 # fraction of the drive/witness peak current for filtering\n",
    "\n",
    "sorted_bc14BLEN = np.sort(bc14BLEN)\n",
    "sort_BC14BLEN_indices = np.argsort(bc14BLEN)\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "bunchSeparation_minus_90 = np.zeros(len(minus_90_idx))\n",
    "currentRatio_minus_90 = np.zeros(len(minus_90_idx))\n",
    "\n",
    "for ij in range(len(minus_90_idx)):\n",
    "    profile = currentProfile_minus_90[ij, :]\n",
    "    peaks, properties = find_peaks(profile)\n",
    "    prominences = properties.get(\"prominences\", profile[peaks])  # fallback to height if no prominences\n",
    "\n",
    "    if len(prominences) < 2:\n",
    "        bunchSeparation_minus_90[ij] = 0\n",
    "        continue\n",
    "\n",
    "    top2_indices = np.argsort(prominences)[-2:]\n",
    "    pos = peaks[top2_indices]\n",
    "\n",
    "    peak_separation = abs(pos[0] - pos[1])\n",
    "\n",
    "    if abs(prominences[top2_indices[0]]) * separationCutoff > abs(prominences[top2_indices[1]]):\n",
    "        peak_separation = 0\n",
    "\n",
    "    bunchSeparation_minus_90[ij] = peak_separation * xtcalibrationfactor\n",
    "    currentRatio_minus_90[ij] = profile[pos[0]] / profile[pos[1]]\n",
    "\n",
    "bunchSeparation_plus_90 = np.zeros(len(plus_90_idx))\n",
    "currentRatio_plus_90 = np.zeros(len(plus_90_idx))\n",
    "\n",
    "for ij in range(len(plus_90_idx)):\n",
    "    profile = currentProfile_plus_90[ij, :]\n",
    "    peaks, properties = find_peaks(profile)\n",
    "    prominences = properties.get(\"prominences\", profile[peaks])\n",
    "\n",
    "    if len(prominences) < 2:\n",
    "        bunchSeparation_plus_90[ij] = 0\n",
    "        continue\n",
    "\n",
    "    top2_indices = np.argsort(prominences)[-2:]\n",
    "    pos = peaks[top2_indices]\n",
    "\n",
    "    peak_separation = abs(pos[0] - pos[1])\n",
    "\n",
    "    if abs(prominences[top2_indices[0]]) * separationCutoff > abs(prominences[top2_indices[1]]):\n",
    "        peak_separation = 0\n",
    "\n",
    "    bunchSeparation_plus_90[ij] = peak_separation * xtcalibrationfactor\n",
    "    currentRatio_plus_90[ij] = profile[pos[0]] / profile[pos[1]]\n",
    "\n",
    "# Convert to microns\n",
    "bunch_sep_minus_90_um = bunchSeparation_minus_90 * 3e8 * 1e6\n",
    "bunch_sep_plus_90_um = bunchSeparation_plus_90 * 3e8 * 1e6\n",
    "\n",
    "# Create figure and primary y-axis\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot bunch separations\n",
    "ln1 = ax1.plot(minus_90_idx, bunch_sep_minus_90_um, '*b', label='-90 deg')\n",
    "ln2 = ax1.plot(plus_90_idx, bunch_sep_plus_90_um, '*r', label='+90 deg')\n",
    "\n",
    "ax1.set_xlabel('Shot Number')\n",
    "ax1.set_ylabel('Bunch Separation [μm]', color='black')\n",
    "ax1.set_ylim(0, 200)  \n",
    "\n",
    "# Create secondary y-axis for BC14 BLEN\n",
    "ax2 = ax1.twinx()\n",
    "shot_numbers = np.arange(bc14BLEN.shape[1])\n",
    "ln3 = ax2.plot(shot_numbers,bc14BLEN[0], color = 'orange', linewidth=0.5)\n",
    "ax2.set_ylabel('BC14 BLEN', color='black')\n",
    "ax2.set_ylim(0, 18000)\n",
    "\n",
    "# Combine legends\n",
    "lines = ln1 + ln2 \n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='upper left')\n",
    "\n",
    "# Title and appearance\n",
    "plt.title(f'TCAV Bunch Separation DAQ {experiment} - {runname}')\n",
    "plt.xlim((-100,2100))\n",
    "fig.tight_layout()\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the charge in the drive and witness beams based on DTOTR projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = data_struct.scalars.steps[DTOTR2commonind]\n",
    "energyProjection = np.sum(xtcavImages, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(energyProjection, aspect='auto', cmap='jet')\n",
    "plt.title(\"Energy Projection\")\n",
    "plt.xlabel(\"Shot Number\")\n",
    "plt.ylabel(\"Vertical Pixel Index\")\n",
    "plt.colorbar(label='Intensity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxDrive = 115 # index in the energy projection that separates Drive-witness - determine it by looking at the above waterfall plot\n",
    "\n",
    "driveBeamEnergyProj = energyProjection[:idxDrive, :] \n",
    "witnessBeamEnergyProj = energyProjection[idxDrive:, :] \n",
    "\n",
    "chargeInDrive = charge * np.sum(driveBeamEnergyProj, axis=0) / np.sum(energyProjection, axis=0)\n",
    "chargeInWitness = charge * np.sum(witnessBeamEnergyProj, axis=0) / np.sum(energyProjection, axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax1 = plt.gca()\n",
    "\n",
    "# Left y-axis\n",
    "ax1.set_ylabel('Bunch Charge [nC]')\n",
    "ax1.set_ylim(0, 1)\n",
    "ln1 = ax1.plot(chargeInDrive[0] * 1e9, '.', label='Drive', ms = 4)\n",
    "ln2 = ax1.plot(chargeInWitness[0] * 1e9, '.r', label='Witness', ms = 4)\n",
    "\n",
    "# Right y-axis (step values)\n",
    "ax2 = ax1.twinx()\n",
    "ln3 = ax2.plot(steps, '-', color='orange', label='Step Value')\n",
    "ax2.set_ylabel('Step Value')\n",
    "\n",
    "# X-axis\n",
    "ax1.set_xlabel('Shot Number')\n",
    "ax1.set_xlim([0, len(steps)])\n",
    "\n",
    "# Combine legend from both axes\n",
    "lines = ln1 + ln2 \n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='upper left')\n",
    "\n",
    "plt.title(f'DTOTR2 Bunch Charge DAQ {experiment} - {runname}')\n",
    "plt.tight_layout()\n",
    "plt.gcf().set_facecolor('white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now fit a 2D function to the data an plot the surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data\n",
    "X = bc14BLEN[0][plus_90_idx]\n",
    "Y = steps[plus_90_idx]\n",
    "Z = bunch_sep_plus_90_um # in microns \n",
    "\n",
    "# Filter good shots\n",
    "goodShots = np.where((Z < 250) & (Z > 0))\n",
    "X = X[goodShots]\n",
    "Y = Y[goodShots]\n",
    "Z = Z[goodShots]\n",
    "\n",
    "# Combine X and Y into a matrix with two columns\n",
    "XY = np.column_stack((X, Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a polynomial surface to the data\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.interpolate import griddata\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "fit_deg = 2\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(fit_deg), LinearRegression())\n",
    "model.fit(XY, Z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid for plotting\n",
    "N = 200\n",
    "x = np.linspace(np.min(X), np.max(X), N)\n",
    "y = np.linspace(np.min(Y), np.max(Y), N)\n",
    "Xi, Yi = np.meshgrid(x, y)\n",
    "\n",
    "# Evaluate the model on a grid\n",
    "grid_points = np.vstack((Xi.ravel(), Yi.ravel())).T\n",
    "Zi_fit = model.predict(grid_points).reshape(Xi.shape)\n",
    "# Interpolate original Z data onto the grid\n",
    "Zi_data = griddata((X, Y), Z, (Xi, Yi), method='linear')\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot original data\n",
    "ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "surf1 = ax1.plot_surface(Xi, Yi, Zi_data, cmap='jet', edgecolor='none')\n",
    "ax1.set_title('Original Data (+90°)')\n",
    "ax1.set_xlabel('BC14 BLEN')\n",
    "ax1.set_ylabel('Step Number')\n",
    "fig.colorbar(surf1, ax=ax1, label='Bunch Sep. [μm]')\n",
    "ax1.set_zlim(0, 250)\n",
    "\n",
    "# Plot fitted model\n",
    "ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "surf2 = ax2.plot_surface(Xi, Yi, Zi_fit, cmap='jet', edgecolor='none')\n",
    "ax2.set_title('Fitted Model (+90°)')\n",
    "ax2.set_xlabel('BC14 BLEN')\n",
    "ax2.set_ylabel('Step Number')\n",
    "fig.colorbar(surf2, ax=ax2, label='Bunch Sep. [μm]')\n",
    "ax2.set_zlim(0, 250)\n",
    "\n",
    "plt.suptitle(f'DTOTR2 Bunch Separation Fit vs Original (+90°) — {experiment} - {runname}', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the bunch length in the drive and witness beams by fitting a biGaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit bi-Gaussian to -90 deg \n",
    "\n",
    "# Define the bi-Gaussian function\n",
    "def bi_gaussian(x, A1, mu1, sigma1, A2, mu2, sigma2):\n",
    "    return (A1 * np.exp(-(x - mu1)**2 / (2 * sigma1**2)) +\n",
    "            A2 * np.exp(-(x - mu2)**2 / (2 * sigma2**2)))\n",
    "\n",
    "mean1 = []\n",
    "mean2 = []\n",
    "sigma1 = []\n",
    "sigma2 = []\n",
    "R_squared = []\n",
    "\n",
    "for ij in range(len(minus_90_idx)):\n",
    "    y = currentProfile_minus_90[ij, :]\n",
    "    x = np.arange(len(y))\n",
    "\n",
    "    # Initial guess: [A1, mu1, sigma1, A2, mu2, sigma2]\n",
    "    initial_guess = [np.max(y), 100, 4, np.max(y)*0.1, 50 + ij * 0.05, 4]\n",
    "\n",
    "    try:\n",
    "        popt, pcov = curve_fit(bi_gaussian, x, y, p0=initial_guess, maxfev=5000)\n",
    "    except RuntimeError:\n",
    "        print(f\"Fit failed at index {ij}\")\n",
    "        mean1.append(np.nan)\n",
    "        mean2.append(np.nan)\n",
    "        sigma1.append(np.nan)\n",
    "        sigma2.append(np.nan)\n",
    "        R_squared.append(np.nan)\n",
    "        continue\n",
    "\n",
    "    # Extract parameters\n",
    "    A1, mu1_val, sig1, A2, mu2_val, sig2 = popt\n",
    "    mean1.append(mu1_val)\n",
    "    mean2.append(mu2_val)\n",
    "    sigma1.append(sig1)\n",
    "    sigma2.append(sig2)\n",
    "\n",
    "    # Evaluate fit\n",
    "    y_fit = bi_gaussian(x, *popt)\n",
    "    SST = np.sum((y - np.mean(y))**2)\n",
    "    SSR = np.sum((y - y_fit)**2)\n",
    "    R_squared.append(1 - SSR / SST)\n",
    "\n",
    "# Convert results to arrays\n",
    "mean1 = np.array(mean1)\n",
    "mean2 = np.array(mean2)\n",
    "sigma1 = np.array(sigma1)\n",
    "sigma2 = np.array(sigma2)\n",
    "R_squared = np.array(R_squared)\n",
    "\n",
    "# Plot the sigma of the drive and witness\n",
    "# Plot the data and the fit\n",
    "zvar = tvar * 3e8 * 1e6  # in microns\n",
    "sigmadrive_minus90 = sigma1 * abs(zvar[1] - zvar[0])\n",
    "sigmawit_minus90 = sigma2 * abs(zvar[1] - zvar[0])\n",
    "\n",
    "# Plot a single fit (last one by default)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, y, 'b.', label='Data', ms = 3)\n",
    "plt.plot(x, bi_gaussian(x, *popt), 'r-', label='Fitted Bi-Gaussian', linewidth = 1)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Signal')\n",
    "plt.title('Bi-Gaussian Fit')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit bi-Gaussian to +90 deg \n",
    "\n",
    "# Define the bi-Gaussian function\n",
    "def bi_gaussian(x, A1, mu1, sigma1, A2, mu2, sigma2):\n",
    "    return (A1 * np.exp(-(x - mu1)**2 / (2 * sigma1**2)) +\n",
    "            A2 * np.exp(-(x - mu2)**2 / (2 * sigma2**2)))\n",
    "\n",
    "mean1 = []\n",
    "mean2 = []\n",
    "sigma1 = []\n",
    "sigma2 = []\n",
    "R_squared = []\n",
    "\n",
    "for ij in range(len(plus_90_idx)):\n",
    "    y = currentProfile_plus_90[ij, :]\n",
    "    x = np.arange(len(y))\n",
    "\n",
    "    # Initial guess: [A1, mu1, sigma1, A2, mu2, sigma2]\n",
    "    initial_guess = [np.max(y), 100, 4, np.max(y)*0.1, 50 + ij * 0.05, 4]\n",
    "\n",
    "    try:\n",
    "        popt, pcov = curve_fit(bi_gaussian, x, y, p0=initial_guess, maxfev=5000)\n",
    "    except RuntimeError:\n",
    "        print(f\"Fit failed at index {ij}\")\n",
    "        mean1.append(np.nan)\n",
    "        mean2.append(np.nan)\n",
    "        sigma1.append(np.nan)\n",
    "        sigma2.append(np.nan)\n",
    "        R_squared.append(np.nan)\n",
    "        continue\n",
    "\n",
    "    # Extract parameters\n",
    "    A1, mu1_val, sig1, A2, mu2_val, sig2 = popt\n",
    "    mean1.append(mu1_val)\n",
    "    mean2.append(mu2_val)\n",
    "    sigma1.append(sig1)\n",
    "    sigma2.append(sig2)\n",
    "\n",
    "    # Evaluate fit\n",
    "    y_fit = bi_gaussian(x, *popt)\n",
    "    SST = np.sum((y - np.mean(y))**2)\n",
    "    SSR = np.sum((y - y_fit)**2)\n",
    "    R_squared.append(1 - SSR / SST)\n",
    "\n",
    "# Convert results to arrays\n",
    "mean1 = np.array(mean1)\n",
    "mean2 = np.array(mean2)\n",
    "sigma1 = np.array(sigma1)\n",
    "sigma2 = np.array(sigma2)\n",
    "R_squared = np.array(R_squared)\n",
    "\n",
    "# Plot the sigma of the drive and witness\n",
    "# Plot the data and the fit\n",
    "zvar = tvar * 3e8 * 1e6  # in microns\n",
    "sigmadrive_minus90 = sigma1 * abs(zvar[1] - zvar[0])\n",
    "sigmawit_minus90 = sigma2 * abs(zvar[1] - zvar[0])\n",
    "\n",
    "# Plot a single fit (last one by default)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, y, 'b.', label='Data', ms = 3)\n",
    "plt.plot(x, bi_gaussian(x, *popt), 'r-', label='Fitted Bi-Gaussian', linewidth = 1)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Signal')\n",
    "plt.title('Bi-Gaussian Fit')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for ML model prediction of the driver current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driverPeak = np.max(currentProfile_plus_90, axis = 1)\n",
    "predictor = bsaScalarData[:,plus_90_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation coefficient between image data and all bsa scalar PVs\n",
    "    # cut out all the shots with l2 phase of 38 deg;\n",
    "c = []\n",
    "\n",
    "for n in range(predictor.shape[0]):\n",
    "    x = predictor[n, :]\n",
    "    y = driverPeak\n",
    "    R = np.corrcoef(x, y)\n",
    "    c.append(R[0, 1])\n",
    "\n",
    "c = np.array(c)\n",
    "absc = np.abs(c)\n",
    "idx = np.argsort(absc)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(absc[idx], linewidth=2)\n",
    "plt.grid(True)\n",
    "plt.box(True)\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.xticks(ticks=np.arange(len(bsaVars)), labels=np.array(bsaVars)[idx], rotation=45, fontsize=10)\n",
    "plt.xlim([0, len(absc)])\n",
    "plt.title(f'Corr. between CHER xctr and scalar PVs DAQ {experiment} - {runname}')\n",
    "plt.gca().tick_params(axis='both', labelsize=14)\n",
    "plt.gcf().set_facecolor('white')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vtcav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
