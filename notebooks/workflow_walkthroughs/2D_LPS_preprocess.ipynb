{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoload when refreshing notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from types import SimpleNamespace\n",
    "import scipy\n",
    "import warnings\n",
    "from scipy.ndimage import median_filter, gaussian_filter\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# import Python functions \n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from Python_Functions.functions import cropProfmonImg, matstruct_to_dict, extractDAQBSAScalars, segment_centroids_and_com, plot2DbunchseparationVsCollimatorAndBLEN, extract_processed_images, apply_centroid_correction, apply_tcav_zeroing_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define XTCAV calibration\n",
    "krf = 239.26\n",
    "cal = 1167 # um/deg  http://physics-elog.slac.stanford.edu/facetelog/show.jsp?dir=/2025/11/13.03&pos=2025-$\n",
    "streakFromGUI = cal*krf*180/np.pi*1e-6#um/um\n",
    "\n",
    "# Sets the main beam energy\n",
    "mainbeamE_eV = 10e9\n",
    "# Sets the dnom value for CHER\n",
    "dnom = 59.8e-3\n",
    "\n",
    "# Sets data location\n",
    "experiment = 'E338' #'E300' 'E338'\n",
    "runname = '12716' #'12431' '12710'\n",
    "step_list = [0,1,2,3,4,5,6] # steps to process, starting from 0\n",
    "## Below value MUST be specified for DAQs with unwanted refraction patterns, etc.\n",
    "roi_xrange = (400, 700)#For run 12710: (400, 700)\n",
    "roi_yrange = (400, 700)#For run 12710: (400, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads dataset\n",
    "dataloc = '../../data/raw/' + experiment + '/' + experiment + '_' + runname + '/' + experiment + '_'  +runname + '.mat'\n",
    "mat = loadmat(dataloc,struct_as_record=False, squeeze_me=True)\n",
    "data_struct = mat['data_struct']\n",
    "\n",
    "# Extracts number of steps\n",
    "stepsAll = data_struct.params.stepsAll\n",
    "if stepsAll is None or len(np.atleast_1d(stepsAll)) == 0:\n",
    "    stepsAll = [1]\n",
    "\n",
    "# calculate xt calibration factor\n",
    "xtcalibrationfactor = data_struct.metadata.DTOTR2.RESOLUTION*1e-6/streakFromGUI/3e8\n",
    "\n",
    "# cropping aspect ratio \n",
    "xrange = 100 \n",
    "yrange = xrange\n",
    "\n",
    "\n",
    "# gaussian filter parameter\n",
    "hotPixThreshold = 1e3\n",
    "sigma = 1\n",
    "threshold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take at most five steps\n",
    "step_list = stepsAll[step_list]\n",
    "print(\"Processing steps:\", step_list)\n",
    "bsaScalarData, bsaVars = extractDAQBSAScalars(data_struct, step_list)\n",
    "bsaScalarData = apply_tcav_zeroing_filter(bsaScalarData, bsaVars)\n",
    "\n",
    "ampl_idx = next(i for i, var in enumerate(bsaVars) if 'TCAV_LI20_2400_A' in var)\n",
    "xtcavAmpl = bsaScalarData[ampl_idx, :]\n",
    "\n",
    "phase_idx = next(i for i, var in enumerate(bsaVars) if 'TCAV_LI20_2400_P' in var)\n",
    "xtcavPhase = bsaScalarData[phase_idx, :]\n",
    "\n",
    "xtcavOffShots = xtcavAmpl<0.1\n",
    "xtcavPhase[xtcavOffShots] = 0 #Set this for ease of plotting\n",
    "\n",
    "isChargePV = [bool(re.search(r'TORO_LI20_2452_TMIT', pv)) for pv in bsaVars]\n",
    "pvidx = [i for i, val in enumerate(isChargePV) if val]\n",
    "charge = bsaScalarData[pvidx, :] * 1.6e-19  # in C \n",
    "\n",
    "minus_90_idx = np.where((xtcavPhase >= -91) & (xtcavPhase <= -89))[0]\n",
    "plus_90_idx = np.where((xtcavPhase >= 89) & (xtcavPhase <= 91))[0]\n",
    "off_idx = np.where(xtcavPhase == 0)[0]\n",
    "all_idx = np.append(minus_90_idx,plus_90_idx)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Index Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i th image can be found at images.instrument_name.common_index[i] of the file images.instrument_name.loc\n",
    "\n",
    "\n",
    "The corresponding i th scalar is at scalars.bsa_name[scalars.common_index[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the interval for inspection\n",
    "STEP_SIZE = 1\n",
    "START = 590\n",
    "END = 610\n",
    "\n",
    "# Extract the arrays\n",
    "dtotr2_data = data_struct.images.DTOTR2.common_index\n",
    "scalars_data = data_struct.scalars.common_index\n",
    "step_data = data_struct.scalars.steps[scalars_data]\n",
    "\n",
    "# 1. Get the indices for every Nth row (e.g., 0, 50, 100, ...)\n",
    "all_indices = np.arange(len(dtotr2_data))\n",
    "filtered_indices = all_indices[START:END:STEP_SIZE]\n",
    "\n",
    "# 2. Filter the data arrays using the selected indices\n",
    "filtered_dtotr2 = dtotr2_data[START:END:STEP_SIZE]\n",
    "filtered_scalars = scalars_data[START:END:STEP_SIZE]\n",
    "filtered_steps = step_data[START:END:STEP_SIZE]\n",
    "\n",
    "# 3. Create a pandas DataFrame for structured output\n",
    "data = {\n",
    "    f'Row Index (Every {STEP_SIZE}th)': filtered_indices,\n",
    "    'DTOTR2 Common Index': filtered_dtotr2,\n",
    "    'Scalars Common Index': filtered_scalars,\n",
    "    # Optional: Calculate the difference between the two indices\n",
    "    'Scalar Step': filtered_steps\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(data)\n",
    "\n",
    "# --- Print the Comparison Table ---\n",
    "print(f\"--- Comparison of Common Indices (Every {STEP_SIZE}th Row) ---\\n\")\n",
    "\n",
    "# Configure pandas to display all rows and columns without truncation\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000) # Set a reasonable width for display\n",
    "\n",
    "# Print the comparison table\n",
    "print(comparison_df)\n",
    "\n",
    "# Reset display options (optional, good practice)\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')\n",
    "pd.reset_option('display.width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract current profiles and 2D LPS images \n",
    "xtcavImages_list = []\n",
    "xtcavImages_list_raw = []\n",
    "horz_proj_list = []\n",
    "LPSImage = [] \n",
    "xtcavImages_centroid_uncorrected, xtcavImages_raw, horz_proj, LPSImage = extract_processed_images(data_struct, experiment, xrange, yrange, hotPixThreshold, sigma, threshold, step_list, roi_xrange, roi_yrange)\n",
    "print(LPSImage.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Centroid Correction (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtcavImages, horz_proj, LPSImage, centroid_corrections = apply_centroid_correction(xtcavImages_centroid_uncorrected, off_idx)\n",
    "print(LPSImage.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Profile Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentProfile_all = [] \n",
    "\n",
    "# Process all degree shots\n",
    "for ij in range(len(all_idx)):\n",
    "    idx = all_idx[ij]\n",
    "    streakedProfile = horz_proj[:,idx]\n",
    "\n",
    "    tvar = np.arange(1, len(streakedProfile) + 1) * xtcalibrationfactor\n",
    "    tvar = tvar - np.median(tvar)  # Center around zero\n",
    "\n",
    "    prefactor = charge[0, idx] / np.trapz(streakedProfile, tvar)\n",
    "\n",
    "    currentProfile = 1e-3 * streakedProfile * prefactor  # Convert to kA\n",
    "    currentProfile_all.append(currentProfile)\n",
    "    \n",
    "currentProfile_all = np.array(currentProfile_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "# Find the first shot where tcav is at -90, 0 and +90 deg\n",
    "def plot_sample_images(idx):\n",
    "    near_minus_90_idx = np.where((xtcavPhase >= -90.55) & (xtcavPhase <= -89.55))[0][idx]\n",
    "    near_plus_90_idx = np.where((xtcavPhase >= 89.55) & (xtcavPhase <= 90.55))[0][idx]\n",
    "    zero_idx = np.where(xtcavPhase == 0)[0][idx]\n",
    "\n",
    "    sample_image_indices = [near_minus_90_idx, zero_idx, near_plus_90_idx]\n",
    "    plot_titles = ['Tcav phase -90 deg', '0 deg', '+90 deg']\n",
    "\n",
    "\n",
    "    # Define the x and yrange for cropping the image; Need to automate this\n",
    "    # figure;imagesc(sampleImage)\n",
    "\n",
    "    xrange = 100\n",
    "    yrange = xrange\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(12, 6), gridspec_kw={'width_ratios': [1, 1, 1, 0.1]})\n",
    "    fig.suptitle(f'TCAV images RAW DAQ {experiment} - {runname}', fontsize=14)\n",
    "\n",
    "    for i, idx in enumerate(sample_image_indices):\n",
    "        if idx is None:\n",
    "            continue\n",
    "\n",
    "        sample_image = xtcavImages_raw[:, :, idx]\n",
    "\n",
    "        axs[i].imshow(sample_image, cmap='jet', aspect='auto')\n",
    "        axs[i].set_title(plot_titles[i])\n",
    "\n",
    "    # Colorbar, top right corner, horizontal\n",
    "    cbar = fig.colorbar(axs[2].images[0], cax = axs[3], orientation='vertical', fraction=0.05, pad=0.2)\n",
    "    cbar.set_label('Intensity [a.u.]')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "    fig.suptitle(f'TCAV images before centroid correction DAQ {experiment} - {runname}', fontsize=14)\n",
    "\n",
    "    for i, idx in enumerate(sample_image_indices):\n",
    "        if idx is None:\n",
    "            continue\n",
    "\n",
    "        sample_image = xtcavImages_centroid_uncorrected[:, :, idx]\n",
    "        horz_proj = np.sum(sample_image, axis=0)\n",
    "\n",
    "        axs[0, i].imshow(sample_image, cmap='jet', aspect='auto')\n",
    "        axs[0, i].set_title(plot_titles[i])\n",
    "\n",
    "        axs[1, i].plot(horz_proj)\n",
    "        axs[1, i].set_title(\"Horizontal Projection\")\n",
    "        #If i==1, the center plot, also plot centroid_corrections on the 2d image\n",
    "        if i==1:\n",
    "            for row in range(sample_image.shape[0]):\n",
    "                shift = centroid_corrections[row]\n",
    "                # Plot a dot at (shift, row)\n",
    "                axs[0, i].plot(xrange - shift, row, 'wo', markersize=1)\n",
    "\n",
    "            # Draw a vertical line at the center of mass x\n",
    "            center_of_mass_x = np.sum(horz_proj * np.arange(horz_proj.shape[0])) / np.sum(horz_proj)\n",
    "            axs[0, i].axvline(center_of_mass_x, color='w', linestyle='--')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "    fig.suptitle(f'TCAV images after centroid correction DAQ {experiment} - {runname}', fontsize=14)\n",
    "\n",
    "    for i, idx in enumerate(sample_image_indices):\n",
    "        if idx is None:\n",
    "            continue\n",
    "\n",
    "        sample_image = xtcavImages[:, :, idx]\n",
    "        horz_proj = np.sum(sample_image, axis=0)\n",
    "\n",
    "        axs[0, i].imshow(sample_image, cmap='jet', aspect='auto')\n",
    "        axs[0, i].set_title(plot_titles[i])\n",
    "\n",
    "        axs[1, i].plot(horz_proj)\n",
    "        axs[1, i].set_title(\"Horizontal Projection\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "interact(plot_sample_images, idx=IntSlider(min=0, max=40, step=1, value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Good Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out \"bad\" shots with Bi-Gaussian fit \n",
    "def bi_gaussian(x, A1, mu1, sigma1, A2, mu2, sigma2):\n",
    "    return (A1 * np.exp(-(x - mu1)**2 / (2 * sigma1**2)) +\n",
    "            A2 * np.exp(-(x - mu2)**2 / (2 * sigma2**2)))\n",
    "\n",
    "amp1 = []\n",
    "amp2 = []\n",
    "mu1 = []\n",
    "mu2 = []\n",
    "R_squared = []\n",
    "#This is 1 based indexing from matlab!!!\n",
    "scalar_common_idx = []\n",
    "\n",
    "# At this point, xtcavImage, currentProfile, LPSImage are already filtered with image common index, hence they are dense from 0 to N-(some lost images).\n",
    "# bsaScalarData and xtcavPhase are filtered with scalar common index too, so xtcavImage[i] corresponds to bsaScalarData[i] and xtcavPhase[i].\n",
    "# However, we still have to store the scalar indices in the pickle if we want to map back to scalars in a different notebook.\n",
    "for ij in range(xtcavImages.shape[2]):\n",
    "    scal_idx = data_struct.scalars.common_index[ij]\n",
    "    # Corresponding scalar index\n",
    "    scalar_common_idx.append(scal_idx)\n",
    "    # For y, instead of using current profile which depends on xtcavPhase, we use vertical projection of the xtcav image, which should always have two peaks for two-bunch shots.\n",
    "    y = np.sum(xtcavImages[:, :, ij], axis=0)\n",
    "    x = np.arange(len(y))\n",
    "\n",
    "    # Initial guess: [A1, mu1, sigma1, A2, mu2, sigma2]\n",
    "    initial_guess = [np.max(y), 80, 4, np.max(y)*0.5, 120, 4]\n",
    "    \n",
    "    try:\n",
    "        popt, pcov = curve_fit(bi_gaussian, x, y, p0=initial_guess, maxfev=5000)\n",
    "    except RuntimeError:\n",
    "        amp1.append(np.nan)\n",
    "        amp2.append(np.nan)\n",
    "        R_squared.append(np.nan)\n",
    "        continue\n",
    "\n",
    "    # Extract parameters\n",
    "    A1, mu1_val, sig1, A2, mu2_val, sig2 = popt\n",
    "    amp1.append(A1)\n",
    "    amp2.append(A2)\n",
    "    mu1.append(mu1_val)\n",
    "    mu2.append(mu2_val)\n",
    "\n",
    "    # Evaluate fit\n",
    "    y_fit = bi_gaussian(x, *popt)\n",
    "    SST = np.sum((y - np.mean(y))**2)\n",
    "    SSR = np.sum((y - y_fit)**2)\n",
    "    R_squared.append(1 - SSR / SST)\n",
    "\n",
    "# Convert results to arrays\n",
    "amp1 = np.array(amp1)\n",
    "amp2 = np.array(amp2)\n",
    "R_squared = np.array(R_squared)\n",
    "scalar_common_idx = np.array(scalar_common_idx)\n",
    "# set requirements for \"good\" shots. For xtcavPhase>0, we want larger (A1) peak at larger x (mu1).\n",
    "# For xtcavPhase<0, we want larger (A2) peak at smaller x (mu2).\n",
    "goodShots = np.where((R_squared > 0.97) & (amp1 > 100) & (amp2 > 100))[0]\n",
    "#goodShots_twobunch_tcav = np.where((R_squared > 0.97) & (amp1 < 50) & ((mu1 > mu2) & (amp1 < amp2)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some good shots xtcavOffShots\n",
    "def plot_goodshot_sample_images(idx):\n",
    "    fig, (ax1) = plt.subplots(1,1,figsize=(9, 6))\n",
    "    im1 = ax1.imshow(xtcavImages[:,:,goodShots[idx]], cmap = \"jet\",aspect='auto')\n",
    "    # ax1.suptitle(f\"Current Profile Index: {idx}\")\n",
    "    # XTCAV phase print\n",
    "    ax1.set_title(f'TCAV image at phase {xtcavPhase[goodShots[idx]]:.2f} deg')\n",
    "    cbar1 = plt.colorbar(im1, ax=ax1)\n",
    "    cbar1.set_label(\"Charge(a.u.)\")\n",
    "    plt.show()\n",
    "interact(plot_goodshot_sample_images, idx=IntSlider(min=0, max=len(goodShots)-1, step=1, value=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ImportError(\"Stop here before saving the preprocessed data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# --- Filter the data based on the indexing logic from the MLP setup cell ---\n",
    "\n",
    "LPSImage_good = LPSImage[goodShots,:]\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# 1. Define the filename\n",
    "filename = f'../../data/processed/LPSImage_goodshots_{experiment}_{runname}_{step_list[0]}.pkl'\n",
    "\n",
    "data_to_save = {\n",
    "    'LPSImage': LPSImage_good,\n",
    "    #This is 1 based indexing from matlab!!!\n",
    "    'scalarCommonIndex': scalar_common_idx[goodShots],\n",
    "    'description': '2D LPS Images (flattened) for good shots only, filtered by all_idx and then goodShots.'\n",
    "}\n",
    "\n",
    "# 2. Save the data using pickle\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(data_to_save, f)\n",
    "print(f\"Successfully saved good shot LPSImage data to '{filename}'.\")\n",
    "print(f\"Saved LPSImage_good shape: {LPSImage_good.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vtcav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
