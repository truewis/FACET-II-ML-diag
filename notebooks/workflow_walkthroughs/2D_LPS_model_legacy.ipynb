{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoload when refreshing notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from types import SimpleNamespace\n",
    "import scipy\n",
    "import warnings\n",
    "from scipy.ndimage import median_filter, gaussian_filter\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# import Python functions \n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from Python_Functions.functions import cropProfmonImg, matstruct_to_dict, extractDAQBSAScalars, segment_centroids_and_com, plot2DbunchseparationVsCollimatorAndBLEN, extract_processed_images, apply_centroid_correction, commonIndexFromSteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define XTCAV calibration\n",
    "krf = 239.26\n",
    "cal = 1167 # um/deg  http://physics-elog.slac.stanford.edu/facetelog/show.jsp?dir=/2025/11/13.03&pos=2025-$\n",
    "streakFromGUI = cal*krf*180/np.pi*1e-6#um/um\n",
    "\n",
    "# Sets the main beam energy\n",
    "mainbeamE_eV = 10e9\n",
    "# Sets the dnom value for CHER\n",
    "dnom = 59.8e-3\n",
    "\n",
    "# Sets data location\n",
    "experiment = 'E338' #'E300' 'E338'\n",
    "runname = '12710' #'12431' '12710'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads dataset\n",
    "dataloc = '../../data/raw/' + experiment + '/' + experiment + '_' + runname + '/' + experiment + '_'  +runname + '.mat'\n",
    "mat = loadmat(dataloc,struct_as_record=False, squeeze_me=True)\n",
    "data_struct = mat['data_struct']\n",
    "\n",
    "# Extracts number of steps\n",
    "stepsAll = data_struct.params.stepsAll\n",
    "if stepsAll is None or len(np.atleast_1d(stepsAll)) == 0:\n",
    "    stepsAll = [1]\n",
    "\n",
    "# calculate xt calibration factor\n",
    "xtcalibrationfactor = data_struct.metadata.DTOTR2.RESOLUTION*1e-6/streakFromGUI/3e8\n",
    "\n",
    "# cropping aspect ratio \n",
    "xrange = 100 \n",
    "yrange = xrange\n",
    "\n",
    "\n",
    "# gaussian filter parameter\n",
    "hotPixThreshold = 1e3\n",
    "sigma = 1\n",
    "threshold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take at most five steps\n",
    "step_list = stepsAll[:3]\n",
    "print(\"Processing steps:\", step_list)\n",
    "bsaScalarData, bsaVars = extractDAQBSAScalars(data_struct, step_list)\n",
    "\n",
    "ampl_idx = next(i for i, var in enumerate(bsaVars) if 'TCAV_LI20_2400_A' in var)\n",
    "xtcavAmpl = bsaScalarData[ampl_idx, :]\n",
    "\n",
    "phase_idx = next(i for i, var in enumerate(bsaVars) if 'TCAV_LI20_2400_P' in var)\n",
    "xtcavPhase = bsaScalarData[phase_idx, :]\n",
    "\n",
    "xtcavOffShots = xtcavAmpl<0.1\n",
    "xtcavPhase[xtcavOffShots] = 0 #Set this for ease of plotting\n",
    "\n",
    "isChargePV = [bool(re.search(r'TORO_LI20_2452_TMIT', pv)) for pv in bsaVars]\n",
    "pvidx = [i for i, val in enumerate(isChargePV) if val]\n",
    "charge = bsaScalarData[pvidx, :] * 1.6e-19  # in C \n",
    "\n",
    "minus_90_idx = np.where((xtcavPhase >= -91) & (xtcavPhase <= -89))[0]\n",
    "plus_90_idx = np.where((xtcavPhase >= 89) & (xtcavPhase <= 91))[0]\n",
    "off_idx = np.where(xtcavPhase == 0)[0]\n",
    "all_idx = np.append(minus_90_idx,plus_90_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract current profiles and 2D LPS images \n",
    "xtcavImages_list = []\n",
    "xtcavImages_list_raw = []\n",
    "horz_proj_list = []\n",
    "LPSImage = [] \n",
    "\n",
    "## Below value MUST be specified for DAQs with unwanted refraction patterns, etc.\n",
    "\n",
    "roi_xrange = (400, 700)\n",
    "roi_yrange = (400, 600)\n",
    "xtcavImages_centroid_uncorrected, xtcavImages_raw, horz_proj, LPSImage = extract_processed_images(data_struct, experiment, xrange, yrange, hotPixThreshold, sigma, threshold, step_list, roi_xrange, roi_yrange)\n",
    "print(LPSImage.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Index Debugging (Could be very confusing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testInd = commonIndexFromSteps(data_struct, [0,1,2,3])\n",
    "print(testInd)\n",
    "print(len(testInd))\n",
    "print(data_struct.images.DTOTR2.common_index - 1)\n",
    "print(data_struct.images.DTOTR2.common_index.shape)\n",
    "print(data_struct.scalars.steps.shape)\n",
    "#print(np.where(data_struct.images.DTOTR2.common_index == 87)[0])\n",
    "DTOTR2commonind = commonIndexFromSteps(data_struct, [0,1,2,3])\n",
    "print(\"Number of shots after applying common index and step range:\", len(DTOTR2commonind))\n",
    "print(np.array(DTOTR2commonind))\n",
    "# Example: If DTOTR2commonind = [0,1,4,6],  new index is [0,1,0,0,2,0,3,...]\n",
    "new_index_list = np.full(np.max(DTOTR2commonind) + 1, -1, dtype=int)\n",
    "new_index_list[DTOTR2commonind] = np.arange(len(DTOTR2commonind))\n",
    "new_index_list[new_index_list == -1] = 0\n",
    "print(new_index_list)\n",
    "print(len(new_index_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam Energy Cross-Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bsaVars)\n",
    "# BPMS_LI20_2445_X is supposed to measure the beam energy right before the TCAV\n",
    "# BPMS_LI14_801_X is supposed to measure the beam energy at LI14\n",
    "# 'BLEN_LI14_888_BRAW' is the length of the bunch at LI14\n",
    "# 'BLEN_LI11_359_BRAW' is the length of the bunch at LI11\n",
    "# 'BPMS_LI11_333_X' is supposed to measure the beam energy at LI11\n",
    "energy_idx = next(i for i, var in enumerate(bsaVars) if 'BPMS_LI11_333_X' in var)\n",
    "beamEnergyM = bsaScalarData[energy_idx, minus_90_idx]\n",
    "beamEnergyP = bsaScalarData[energy_idx, plus_90_idx]\n",
    "beamEnergyO = bsaScalarData[energy_idx, off_idx]\n",
    "# print(beamEnergy)\n",
    "# Create LPS image center of mass y coordinate vs beam energy plot\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(beamEnergyM, np.array([np.sum(xtcavImages_centroid_uncorrected[:,:,i]*np.arange(xtcavImages_centroid_uncorrected.shape[1])[np.newaxis,:])/np.sum(xtcavImages_centroid_uncorrected[:,:,i]) for i in minus_90_idx]), c='blue', s=5)\n",
    "plt.scatter(beamEnergyP, np.array([np.sum(xtcavImages_centroid_uncorrected[:,:,i]*np.arange(xtcavImages_centroid_uncorrected.shape[1])[np.newaxis,:])/np.sum(xtcavImages_centroid_uncorrected[:,:,i]) for i in plus_90_idx]), c='red', s=5)\n",
    "plt.scatter(beamEnergyO, np.array([np.sum(xtcavImages_centroid_uncorrected[:,:,i]*np.arange(xtcavImages_centroid_uncorrected.shape[1])[np.newaxis,:])/np.sum(xtcavImages_centroid_uncorrected[:,:,i]) for i in off_idx]), c='green', s=5)\n",
    "\n",
    "plt.xlabel('BPMS_LI11_333_X')\n",
    "plt.ylabel('LPS Image Center of Mass [pix]')\n",
    "plt.title('LPS Image Center of Mass vs Beam Energy PV, Cropped Image')\n",
    "plt.legend(['-90 deg','+90 deg','0 deg'])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(beamEnergyM, np.array([np.sum(xtcavImages_raw[:,:,i]*np.arange(xtcavImages_raw.shape[1])[np.newaxis,:])/np.sum(xtcavImages_raw[:,:,i]) for i in minus_90_idx]), c='blue', s=5)\n",
    "plt.scatter(beamEnergyP, np.array([np.sum(xtcavImages_raw[:,:,i]*np.arange(xtcavImages_raw.shape[1])[np.newaxis,:])/np.sum(xtcavImages_raw[:,:,i]) for i in plus_90_idx]), c='red', s=5)\n",
    "plt.scatter(beamEnergyO, np.array([np.sum(xtcavImages_raw[:,:,i]*np.arange(xtcavImages_raw.shape[1])[np.newaxis,:])/np.sum(xtcavImages_raw[:,:,i]) for i in off_idx]), c='green', s=5)\n",
    "\n",
    "plt.xlabel('BPMS_LI11_333_X')\n",
    "plt.ylabel('LPS Image Center of Mass [pix]')\n",
    "plt.title('LPS Image Center of Mass vs Beam Energy PV, RAW Image')\n",
    "plt.legend(['-90 deg','+90 deg','0 deg'])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Centroid Correction (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtcavImages, horz_proj, LPSImage, centroid_corrections = apply_centroid_correction(xtcavImages_centroid_uncorrected, off_idx)\n",
    "print(LPSImage.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Profile Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentProfile_all = [] \n",
    "\n",
    "# Process all degree shots\n",
    "for ij in range(len(all_idx)):\n",
    "    idx = all_idx[ij]\n",
    "    streakedProfile = horz_proj[:,idx]\n",
    "\n",
    "    tvar = np.arange(1, len(streakedProfile) + 1) * xtcalibrationfactor\n",
    "    tvar = tvar - np.median(tvar)  # Center around zero\n",
    "\n",
    "    prefactor = charge[0, idx] / np.trapz(streakedProfile, tvar)\n",
    "\n",
    "    currentProfile = 1e-3 * streakedProfile * prefactor  # Convert to kA\n",
    "    currentProfile_all.append(currentProfile)\n",
    "    \n",
    "currentProfile_all = np.array(currentProfile_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "# Find the first shot where tcav is at -90, 0 and +90 deg\n",
    "def plot_sample_images(idx):\n",
    "    near_minus_90_idx = np.where((xtcavPhase >= -90.55) & (xtcavPhase <= -89.55))[0][idx]\n",
    "    near_plus_90_idx = np.where((xtcavPhase >= 89.55) & (xtcavPhase <= 90.55))[0][idx]\n",
    "    zero_idx = np.where(xtcavPhase == 0)[0][idx]\n",
    "\n",
    "    sample_image_indices = [near_minus_90_idx, zero_idx, near_plus_90_idx]\n",
    "    plot_titles = ['Tcav phase -90 deg', '0 deg', '+90 deg']\n",
    "\n",
    "\n",
    "    # Define the x and yrange for cropping the image; Need to automate this\n",
    "    # figure;imagesc(sampleImage)\n",
    "\n",
    "    xrange = 100\n",
    "    yrange = xrange\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(12, 6), gridspec_kw={'width_ratios': [1, 1, 1, 0.1]})\n",
    "    fig.suptitle(f'TCAV images RAW DAQ {experiment} - {runname}', fontsize=14)\n",
    "\n",
    "    for i, idx in enumerate(sample_image_indices):\n",
    "        if idx is None:\n",
    "            continue\n",
    "\n",
    "        sample_image = xtcavImages_raw[:, :, idx]\n",
    "\n",
    "        axs[i].imshow(sample_image, cmap='jet', aspect='auto')\n",
    "        axs[i].set_title(plot_titles[i])\n",
    "\n",
    "    # Colorbar, top right corner, horizontal\n",
    "    cbar = fig.colorbar(axs[2].images[0], cax = axs[3], orientation='vertical', fraction=0.05, pad=0.2)\n",
    "    cbar.set_label('Intensity [a.u.]')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "    fig.suptitle(f'TCAV images before centroid correction DAQ {experiment} - {runname}', fontsize=14)\n",
    "\n",
    "    for i, idx in enumerate(sample_image_indices):\n",
    "        if idx is None:\n",
    "            continue\n",
    "\n",
    "        sample_image = xtcavImages_centroid_uncorrected[:, :, idx]\n",
    "        horz_proj = np.sum(sample_image, axis=0)\n",
    "\n",
    "        axs[0, i].imshow(sample_image, cmap='jet', aspect='auto')\n",
    "        axs[0, i].set_title(plot_titles[i])\n",
    "\n",
    "        axs[1, i].plot(horz_proj)\n",
    "        axs[1, i].set_title(\"Horizontal Projection\")\n",
    "        #If i==1, the center plot, also plot centroid_corrections on the 2d image\n",
    "        if i==1:\n",
    "            for row in range(sample_image.shape[0]):\n",
    "                shift = centroid_corrections[row]\n",
    "                # Plot a dot at (shift, row)\n",
    "                axs[0, i].plot(xrange - shift, row, 'wo', markersize=1)\n",
    "\n",
    "            # Draw a vertical line at the center of mass x\n",
    "            center_of_mass_x = np.sum(horz_proj * np.arange(horz_proj.shape[0])) / np.sum(horz_proj)\n",
    "            axs[0, i].axvline(center_of_mass_x, color='w', linestyle='--')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "    fig.suptitle(f'TCAV images after centroid correction DAQ {experiment} - {runname}', fontsize=14)\n",
    "\n",
    "    for i, idx in enumerate(sample_image_indices):\n",
    "        if idx is None:\n",
    "            continue\n",
    "\n",
    "        sample_image = xtcavImages[:, :, idx]\n",
    "        horz_proj = np.sum(sample_image, axis=0)\n",
    "\n",
    "        axs[0, i].imshow(sample_image, cmap='jet', aspect='auto')\n",
    "        axs[0, i].set_title(plot_titles[i])\n",
    "\n",
    "        axs[1, i].plot(horz_proj)\n",
    "        axs[1, i].set_title(\"Horizontal Projection\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "interact(plot_sample_images, idx=IntSlider(min=0, max=40, step=1, value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Good Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out \"bad\" shots with Bi-Gaussian fit \n",
    "def bi_gaussian(x, A1, mu1, sigma1, A2, mu2, sigma2):\n",
    "    return (A1 * np.exp(-(x - mu1)**2 / (2 * sigma1**2)) +\n",
    "            A2 * np.exp(-(x - mu2)**2 / (2 * sigma2**2)))\n",
    "\n",
    "amp1 = []\n",
    "amp2 = []\n",
    "mu1 = []\n",
    "mu2 = []\n",
    "R_squared = []\n",
    "\n",
    "for ij in range(len(all_idx)):\n",
    "    y = currentProfile_all[ij, :]\n",
    "    x = np.arange(len(y))\n",
    "\n",
    "    # Initial guess: [A1, mu1, sigma1, A2, mu2, sigma2]\n",
    "    if xtcavPhase[all_idx][ij] < 0:\n",
    "        initial_guess = [np.max(y), 100, 4, np.max(y)*0.1, 60 + ij*0.15, 4]\n",
    "    elif xtcavPhase[all_idx][ij] > 0:\n",
    "        initial_guess = [np.max(y), 100, 4, np.max(y)*0.1, 60, 4]\n",
    "    \n",
    "    try:\n",
    "        popt, pcov = curve_fit(bi_gaussian, x, y, p0=initial_guess, maxfev=5000)\n",
    "    except RuntimeError:\n",
    "        amp1.append(np.nan)\n",
    "        R_squared.append(np.nan)\n",
    "        continue\n",
    "\n",
    "    # Extract parameters\n",
    "    A1, mu1_val, sig1, A2, mu2_val, sig2 = popt\n",
    "    amp1.append(A1)\n",
    "    amp2.append(A2)\n",
    "    mu1.append(mu1_val)\n",
    "    mu2.append(mu2_val)\n",
    "\n",
    "    # Evaluate fit\n",
    "    y_fit = bi_gaussian(x, *popt)\n",
    "    SST = np.sum((y - np.mean(y))**2)\n",
    "    SSR = np.sum((y - y_fit)**2)\n",
    "    R_squared.append(1 - SSR / SST)\n",
    "\n",
    "# Convert results to arrays\n",
    "amp1 = np.array(amp1)\n",
    "R_squared = np.array(R_squared)\n",
    "# set requirements for \"good\" shots. For xtcavPhase>0, we want larger (A1) peak at larger x (mu1).\n",
    "# For xtcavPhase<0, we want larger (A2) peak at smaller x (mu2).\n",
    "goodShots = np.where((R_squared > 0.97) & (amp1 < 50))[0]\n",
    "#goodShots_twobunch_tcav = np.where((R_squared > 0.97) & (amp1 < 50) & ((mu1 > mu2) & (amp1 < amp2)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some good shots xtcavOffShots\n",
    "idx = 5\n",
    "fig, (ax1) = plt.subplots(1,1,figsize=(9, 6))\n",
    "im1 = ax1.imshow(xtcavImages[:,:,minus_90_idx[idx]], cmap = \"jet\",aspect='auto')\n",
    "# ax1.suptitle(f\"Current Profile Index: {idx}\")\n",
    "cbar1 = plt.colorbar(im1, ax=ax1)\n",
    "cbar1.set_label(\"Charge(a.u.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "index = np.sort(all_idx[goodShots])\n",
    "images = LPSImage[all_idx,:][goodShots,:]\n",
    "steps = data_struct.scalars.steps[DTOTR2commonind]\n",
    "predictor = np.vstack(bsaScalarData[:,goodShots]).T\n",
    "\n",
    "x_scaler = MinMaxScaler()\n",
    "iz_scaler = MinMaxScaler()\n",
    "x_scaled = x_scaler.fit_transform(predictor)\n",
    "Iz_scaled = iz_scaler.fit_transform(images)\n",
    "\n",
    "# 80/20 train-test split\n",
    "x_train_full, x_test_scaled, Iz_train_full, Iz_test_scaled, ntrain, ntest = train_test_split(\n",
    "    x_scaled, Iz_scaled, index, test_size=0.2, random_state = 42)\n",
    "\n",
    "# 20% validation split \n",
    "x_train_scaled, x_validation, Iz_train_scaled, y_validation = train_test_split(\n",
    "    x_train_full, Iz_train_full, test_size=0.2, random_state = 42)\n",
    "\n",
    "# compress pixels \n",
    "pca = PCA(n_components=100)\n",
    "compressed_targets = pca.fit_transform(Iz_train_scaled) \n",
    "print(Iz_train_scaled.shape, compressed_targets.shape)\n",
    "y_validation = pca.transform(y_validation)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(x_train_scaled, dtype=torch.float32)\n",
    "x_validation = torch.tensor(x_validation, dtype=torch.float32)\n",
    "X_test = torch.tensor(x_test_scaled, dtype=torch.float32)\n",
    "Y_train = torch.tensor(compressed_targets, dtype=torch.float32)\n",
    "y_validation = torch.tensor(y_validation, dtype=torch.float32)\n",
    "Y_test = torch.tensor(Iz_test_scaled, dtype=torch.float32)\n",
    "\n",
    "train_ds = TensorDataset(X_train, Y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=24, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Define MLP structure\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_dim, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000,500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = MLP(X_train.shape[1], Y_train.shape[1])\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Define custom weighted MSE loss function \n",
    "def custom_loss( y_pred,y_true): \n",
    "    mse = (y_true - y_pred)**2\n",
    "    weights = 1 + 0.7*((y_true < 0.2)|(y_true > 0.8)).float()\n",
    "    return torch.mean(weights*mse)\n",
    "\n",
    "# Training loop \n",
    "n_epochs = 200\n",
    "patience = 25\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Fit the nn model on the training set\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = custom_loss(pred, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    avg_train_loss = train_loss / len(train_dl)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation loss\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_pred = model(x_validation)\n",
    "        val_loss = custom_loss(val_pred, y_validation).item()\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = model.state_dict()\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            break\n",
    "    \n",
    "model.load_state_dict(best_model_state)\n",
    "    \n",
    "# Evaluate model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred_train_scaled = model(X_train).numpy()\n",
    "    pred_test_scaled = model(X_test).numpy()\n",
    "\n",
    "# Inverse transform predictions\n",
    "pred_train_full = iz_scaler.inverse_transform(pca.inverse_transform(pred_train_scaled))\n",
    "pred_test_full = iz_scaler.inverse_transform(pca.inverse_transform(pred_test_scaled))\n",
    "Iz_train_true = iz_scaler.inverse_transform(Iz_train_scaled)\n",
    "Iz_test_true = iz_scaler.inverse_transform(Iz_test_scaled)\n",
    "elapsed = time.time() - t0\n",
    "print(\"Elapsed time [mins] = {:.1f} \".format(elapsed/60))\n",
    "\n",
    "# Compute R²\n",
    "def r2_score(true, pred):\n",
    "    RSS = np.sum((true - pred)**2)\n",
    "    TSS = np.sum((true - np.mean(true))**2)\n",
    "    return 1 - RSS / TSS if TSS != 0 else s0\n",
    "\n",
    "print(\"Train R²: {:.2f} %\".format(r2_score(Iz_train_true.ravel(), pred_train_full.ravel()) * 100))\n",
    "print(\"Test R²: {:.2f} %\".format(r2_score(Iz_test_true.ravel(), pred_test_full.ravel()) * 100))\n",
    "\n",
    "# Plot histogram of R² values for each test sample\n",
    "r2_values = [r2_score(Iz_test_true.T.reshape(2*yrange,2*xrange,Iz_test_true.shape[0])[:,:,i], pred_test_full.T.reshape(2*yrange,2*xrange,Iz_test_true.shape[0])[:,:,i]) for i in range(Iz_test_true.shape[0])]\n",
    "# Throw away values outside 0 to 1, and count the number of throws\n",
    "r2_values_new = [r2 for r2 in r2_values if 0 <= r2 <= 1]\n",
    "num_throws = len(r2_values) - len(r2_values_new)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(r2_values_new, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of R² Values for Test Samples')\n",
    "plt.xlabel('R² Value')\n",
    "plt.ylabel(f'Plotted Samples: {len(r2_values) - num_throws} / Total Samples: {len(r2_values)}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of PCA (before MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 15\n",
    "fig, (ax2, ax3, cx2) = plt.subplots(1,3,figsize=(15, 3), gridspec_kw={'width_ratios': [1, 1, 0.02]})\n",
    "before_pca_image = Iz_test_true.T.reshape(2*yrange,2*xrange,Iz_test_true.shape[0])[:,:,idx]\n",
    "#Flip in y direction for proper visualization\n",
    "im2 = ax2.imshow(np.flip(before_pca_image, axis=0), cmap = \"jet\",aspect='auto', vmin = 0, vmax = 400)\n",
    "# ax2.suptitle(f\"Current Profile Index: {idx}\")\n",
    "ax2.set(ylabel=\"y [pix]\")\n",
    "ax2.set(xlabel = \"Time [fs]\")\n",
    "ax2.set_title('Before PCA', fontsize = 12)\n",
    "# ax2.set(title = \"True\", fontsize = 2)\n",
    "ax2.set(xlim = (0,2*xrange))\n",
    "ax2.set(ylim= (0,2*yrange))\n",
    "\n",
    "after_pca_image = pca.inverse_transform(pca.transform(before_pca_image.flatten()[np.newaxis,:])).reshape(2*yrange,2*xrange)\n",
    "\n",
    "im3 = ax3.imshow(np.flip(after_pca_image, axis=0), cmap = \"jet\",aspect='auto', vmin = 0, vmax = 400)\n",
    "ax3.set(xlabel = \"Time [fs]\")\n",
    "ax3.set(ylabel = \"y [pix]\")\n",
    "ax3.set_title('After PCA', fontsize = 12)\n",
    "ax3.set(xlim = (0,2*xrange))\n",
    "ax3.set(ylim= (0,2*yrange))\n",
    "fig.colorbar((im2), cax=cx2, format='%.3g')\n",
    "fig.subplots_adjust(wspace=0.8)\n",
    "#fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "def plot_xtcav_image_pred(idx):\n",
    "    fig, (ax1, ax2, cx1) = plt.subplots(1,3,figsize=(10, 3), gridspec_kw={'width_ratios': [1, 1, 0.02]})\n",
    "    im1 = ax1.imshow(np.flip(Iz_test_true.T.reshape(2*yrange,2*xrange,Iz_test_true.shape[0])[:,:,idx], axis=0), cmap = \"jet\",aspect='auto', vmin = 0, vmax = 400)\n",
    "   \n",
    "    # ax1.suptitle(f\"Current Profile Index: {idx}\")\n",
    "    ax1.set(ylabel=\"y [pix]\")\n",
    "    ax1.set(xlabel = \"Time [fs]\")\n",
    "    ax1.set(title = f\"True(Shot Number: {ntest[idx]})\")\n",
    "    ax1.set(xlim = (0,2*xrange))\n",
    "    ax1.set(ylim= (0,2*yrange))\n",
    "\n",
    "    im2 = ax2.imshow(np.flip(pred_test_full.T.reshape(2*yrange,2*xrange,Iz_test_true.shape[0])[:,:,idx], axis=0), cmap = \"jet\",aspect='auto',vmin = 0, vmax = 400)\n",
    "    ax2.set(xlabel = \"Time [fs]\")\n",
    "    ax2.set(ylabel = \"y [pix]\")\n",
    "    ax2.set(title = \"Prediction\")\n",
    "    ax2.set(xlim = (0,2*xrange))\n",
    "    ax2.set(ylim= (0,2*yrange))\n",
    "    cbar = fig.colorbar(im1, cax=cx1, fraction=0.16, pad=0.04)\n",
    "    # cbar.set_label(\"Current [arb. units]\")\n",
    "    plt.subplots_adjust(wspace=0.4)\n",
    "    # plt.tight_layout()\n",
    "    # fig.show()\n",
    "    # Also plot R² value for this index\n",
    "    r2_val = r2_score(Iz_test_true.T.reshape(2*yrange,2*xrange,Iz_test_true.shape[0])[:,:,idx], pred_test_full.T.reshape(2*yrange,2*xrange,Iz_test_true.shape[0])[:,:,idx])\n",
    "    plt.suptitle(f'R² Value: {r2_val:.4f}', fontsize=7)\n",
    "\n",
    "# Create slider\n",
    "interact(plot_xtcav_image_pred, idx=IntSlider(min=0, max=pred_test_full.shape[0]-1, step=1, value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ImportError(\"Stop here after training and evaluating the model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load From A Different Run For Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load from a different run for prediction\n",
    "experiment_new='E300'\n",
    "runname_new = '12431'\n",
    "dataloc_new = '../../data/raw/' + experiment_new + '/' + experiment_new + '_' + runname_new + '/' + experiment_new + '_'  +runname_new + '.mat'\n",
    "mat_new = loadmat(dataloc_new,struct_as_record=False, squeeze_me=True)\n",
    "data_struct_new = mat_new['data_struct']\n",
    "# Extract current profiles and 2D LPS images\n",
    "xtcavImages_list_newRun = []\n",
    "xtcavImages_list_raw_newRun = []\n",
    "horz_proj_list_newRun = []\n",
    "LPSImage_newRun = []\n",
    "step_list = [1,2,3,4,5]\n",
    "xtcavImages_centroid_uncorrected_newRun, xtcavImages_raw_newRun, horz_proj_newRun, LPSImage_newRun = extract_processed_images(data_struct_new, experiment_new, xrange, yrange, hotPixThreshold, sigma, threshold, step_list)\n",
    "print(LPSImage_newRun.shape)\n",
    "DTOTR2commonind_newRun = commonIndexFromSteps(data_struct_new, step_list)\n",
    "bsaScalarData_newRun, bsaVars_newRun = extractDAQBSAScalars(data_struct_new, DTOTR2commonind_newRun)\n",
    "# Process all degree shots\n",
    "\n",
    "# Take only if steps in step_range\n",
    "xtcavAmpl_newRun_idx = next(i for i, var in enumerate(bsaVars_newRun) if 'TCAV_LI20_2400_A' in var)\n",
    "xtcavAmpl_newRun = bsaScalarData_newRun[xtcavAmpl_newRun_idx, :]\n",
    "xtcavPhase_newRun_idx = next(i for i, var in enumerate(bsaVars_newRun) if 'TCAV_LI20_2400_P' in var)\n",
    "xtcavPhase_newRun = bsaScalarData_newRun[xtcavPhase_newRun_idx, :]\n",
    "xtcavPhase_newRun[xtcavAmpl_newRun<0.1] = 0 #Set this for ease of plotting\n",
    "isChargePV_newRun = [bool(re.search(r'TORO_LI20_2452_TMIT', pv)) for pv in bsaVars_newRun]\n",
    "pvidx_newRun = [i for i, val in enumerate(isChargePV_newRun) if val]\n",
    "charge_newRun = bsaScalarData_newRun[pvidx_newRun, :] * 1.6e-19  # in C \n",
    "minus_90_idx_newRun = np.where((xtcavPhase_newRun >= -91) & (xtcavPhase_newRun <= -89))[0]\n",
    "plus_90_idx_newRun = np.where((xtcavPhase_newRun >= 89) & (xtcavPhase_newRun <= 91))[0]\n",
    "all_idx_newRun = np.append(minus_90_idx_newRun,plus_90_idx_newRun)\n",
    "# Include zero phase shots as well\n",
    "off_idx_newRun = np.where(xtcavPhase_newRun == 0)[0]\n",
    "#Apply centroid correction\n",
    "xtcavImages_newRun, horz_proj_newRun, LPSImage_newRun, centroid_corrections_newRun = apply_centroid_correction(xtcavImages_centroid_uncorrected_newRun, off_idx_newRun)\n",
    "# Extract current profiles\n",
    "currentProfile_all_newRun = [] \n",
    "for ij in range(len(all_idx_newRun)):\n",
    "    idx = all_idx_newRun[ij]\n",
    "    streakedProfile = horz_proj_newRun[:,idx]\n",
    "\n",
    "    tvar = np.arange(1, len(streakedProfile) + 1) * xtcalibrationfactor\n",
    "    tvar = tvar - np.median(tvar)  # Center around zero\n",
    "\n",
    "    prefactor = charge_newRun[0, idx] / np.trapz(streakedProfile, tvar)\n",
    "\n",
    "    currentProfile = 1e-3 * streakedProfile * prefactor  # Convert to kA\n",
    "    currentProfile_all_newRun.append(currentProfile)\n",
    "currentProfile_all_newRun = np.array(currentProfile_all_newRun)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input for prediction\n",
    "index_newRun = np.sort(all_idx_newRun)\n",
    "images_newRun = LPSImage_newRun[all_idx_newRun,:]\n",
    "predictor_newRun = np.vstack((bsaScalarData_newRun[:,all_idx_newRun], data_struct_new.scalars.steps[all_idx_newRun])).T\n",
    "#x_scaled_newRun = x_scaler.transform(predictor_newRun)\n",
    "# Check if scaler worked properly. Values should be between 0 and 1\n",
    "# Clamp values outside 0-1 range\n",
    "# x_scaled_newRun = np.clip(x_scaled_newRun, 0, 1)\n",
    "# Create new MiniMaxScaler for targets to avoid issues with inverse transform\n",
    "x_scaler_newRun = MinMaxScaler()\n",
    "x_scaled_newRun = x_scaler_newRun.fit_transform(predictor_newRun)\n",
    "X_newRun = torch.tensor(x_scaled_newRun, dtype=torch.float32)\n",
    "\n",
    "\n",
    "print(\"Min and Max of scaled inputs for new run:\", np.min(x_scaled_newRun), np.max(x_scaled_newRun))\n",
    "# Make prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred_newRun_scaled = model(X_newRun).numpy()\n",
    "# Inverse transform predictions\n",
    "pred_newRun_full = iz_scaler.inverse_transform(pca.inverse_transform(pred_newRun_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the first shot where tcav is at -90, 0 and +90 deg\n",
    "def plot_sample_images(idxz):\n",
    "    near_minus_90_idx = np.where((xtcavPhase_newRun >= -90.55) & (xtcavPhase_newRun <= -89.55))[0][idxz]\n",
    "    near_plus_90_idx = np.where((xtcavPhase_newRun >= 89.55) & (xtcavPhase_newRun <= 90.55))[0][idxz]\n",
    "    zero_idx = np.where(xtcavPhase_newRun == 0)[0][idxz]\n",
    "\n",
    "    sample_image_indices = [near_minus_90_idx, zero_idx, near_plus_90_idx]\n",
    "    plot_titles = ['Tcav phase -90 deg', '0 deg', '+90 deg']\n",
    "\n",
    "\n",
    "    # Define the x and yrange for cropping the image; Need to automate this\n",
    "    # figure;imagesc(sampleImage)\n",
    "\n",
    "    xrange = 100\n",
    "    yrange = xrange\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(12, 6), gridspec_kw={'width_ratios': [1, 1, 1, 0.1]})\n",
    "    fig.suptitle(f'TCAV images RAW DAQ {experiment_new} - {runname_new}', fontsize=14)\n",
    "\n",
    "    for i, idx in enumerate(sample_image_indices):\n",
    "        if idx is None:\n",
    "            continue\n",
    "\n",
    "        sample_image = xtcavImages_raw_newRun[:, :, idx]\n",
    "\n",
    "        axs[i].imshow(sample_image, cmap='jet', aspect='auto')\n",
    "        axs[i].set_title(plot_titles[i])\n",
    "\n",
    "    # Colorbar, top right corner, horizontal\n",
    "    cbar = fig.colorbar(axs[2].images[0], cax = axs[3], orientation='vertical', fraction=0.05, pad=0.2)\n",
    "    cbar.set_label('Intensity [a.u.]')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "    fig.suptitle(f'TCAV images before centroid correction DAQ {experiment_new} - {runname_new}', fontsize=14)\n",
    "\n",
    "    for i, idx in enumerate(sample_image_indices):\n",
    "        if idx is None:\n",
    "            continue\n",
    "\n",
    "        sample_image = xtcavImages_centroid_uncorrected_newRun[:, :, idx]\n",
    "        horz_proj = np.sum(sample_image, axis=0)\n",
    "\n",
    "        axs[0, i].imshow(sample_image, cmap='jet', aspect='auto')\n",
    "        axs[0, i].set_title(plot_titles[i])\n",
    "\n",
    "        axs[1, i].plot(horz_proj)\n",
    "        axs[1, i].set_title(\"Horizontal Projection\")\n",
    "        #If i==1, the center plot, also plot centroid_corrections on the 2d image\n",
    "        if i==1:\n",
    "            for row in range(sample_image.shape[0]):\n",
    "                shift = centroid_corrections_newRun[row]\n",
    "                # Plot a dot at (shift, row)\n",
    "                axs[0, i].plot(xrange - shift, row, 'wo', markersize=1)\n",
    "\n",
    "            # Draw a vertical line at the center of mass x\n",
    "            center_of_mass_x = np.sum(horz_proj * np.arange(horz_proj.shape[0])) / np.sum(horz_proj)\n",
    "            axs[0, i].axvline(center_of_mass_x, color='w', linestyle='--')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "    fig.suptitle(f'TCAV images after centroid correction DAQ {experiment_new} - {runname_new}', fontsize=14)\n",
    "\n",
    "    for i, idx in enumerate(sample_image_indices):\n",
    "        if idx is None:\n",
    "            continue\n",
    "\n",
    "        sample_image = xtcavImages_newRun[:, :, idx]\n",
    "        horz_proj = np.sum(sample_image, axis=0)\n",
    "\n",
    "        axs[0, i].imshow(sample_image, cmap='jet', aspect='auto')\n",
    "        axs[0, i].set_title(plot_titles[i])\n",
    "\n",
    "        axs[1, i].plot(horz_proj)\n",
    "        axs[1, i].set_title(\"Horizontal Projection\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "interact(plot_sample_images, idxz=IntSlider(min=0, max=40, step=1, value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot R² histogram for new run\n",
    "r2_values_newRun = [r2_score(images_newRun.T.reshape(2*yrange,2*xrange,images_newRun.shape[0])[:,:,i], pred_newRun_full.T.reshape(2*yrange,2*xrange,images_newRun.shape[0])[:,:,i]) for i in range(images_newRun.shape[0])]\n",
    "# Throw away values outside 0 to 1, and count the number of throws\n",
    "r2_values_newRun_filtered = [r2 for r2 in r2_values_newRun if 0 <= r2 <= 1]\n",
    "num_throws_newRun = len(r2_values_newRun) - len(r2_values_newRun_filtered)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(r2_values_newRun_filtered, bins=20, color='lightgreen', edgecolor='black')\n",
    "plt.title('Histogram of R² Values for New Run Samples')\n",
    "plt.xlabel('R² Value')\n",
    "plt.ylabel(f'Plotted Samples: {len(r2_values_newRun) - num_throws_newRun} / Total Samples: {len(r2_values_newRun)}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "# Plot some prediction results from new run\n",
    "# Interactive plot\n",
    "def plot_xtcav_image_newRun(idx):\n",
    "    fig, (ax1, ax2, cx1) = plt.subplots(1,3,figsize=(10, 3), gridspec_kw={'width_ratios': [1, 1, 0.02]})\n",
    "    im1 = ax1.imshow(np.flip(images_newRun.T.reshape(2*yrange,2*xrange,images_newRun.shape[0])[:,:,idx], axis=0), cmap = \"jet\",aspect='auto', vmin = 0, vmax = 400)\n",
    "    # ax1.suptitle(f\"Current Profile Index: {idx}\")\n",
    "    ax1.set(ylabel=\"y [pix]\")\n",
    "    ax1.set(xlabel = \"Time [fs]\")\n",
    "    ax1.set(title = f\"True(Shot Number: {index_newRun[idx]})\")\n",
    "    ax1.set(xlim = (0,2*xrange))\n",
    "    ax1.set(ylim= (0,2*yrange))\n",
    "    im2 = ax2.imshow(np.flip(pred_newRun_full.T.reshape(2*yrange,2*xrange,images_newRun.shape[0])[:,:,idx], axis=0), cmap = \"jet\",aspect='auto',vmin = 0, vmax = 400)\n",
    "    ax2.set(xlabel = \"Time [fs]\")\n",
    "    ax2.set(ylabel = \"y [pix]\")\n",
    "    ax2.set(title = \"Prediction\")\n",
    "    ax2.set(xlim = (0,2*xrange))\n",
    "    ax2.set(ylim= (0,2*yrange))\n",
    "    cbar = fig.colorbar(im1, cax=cx1, fraction=0.16, pad=0.04)\n",
    "    # cbar.set_label(\"Current [arb. units]\")\n",
    "    #Also print corresponding xtcavPhase_newRun_idx and xtcavAmpl_newRun_idx\n",
    "    xtcavPhase_corr = xtcavPhase_newRun[idx]\n",
    "    xtcavAmpl_corr = xtcavAmpl_newRun[idx]\n",
    "    fig.suptitle(f'TCAV Phase: {xtcavPhase_corr:.2f} deg, TCAV Amplitude: {xtcavAmpl_corr:.2f} MV', fontsize=7)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.4)\n",
    "    plt.show()\n",
    "# Create slider\n",
    "interact(plot_xtcav_image_newRun, idx=IntSlider(min=0, max=pred_newRun_full.shape[0]-1, step=1, value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BSA Variable Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # For easy table printing\n",
    "\n",
    "# 1. Calculate statistics for the new run\n",
    "avg_new = np.mean(bsaScalarData_newRun, axis=1)\n",
    "std_new = np.std(bsaScalarData_newRun, axis=1)\n",
    "\n",
    "# 2. Calculate statistics for the old run\n",
    "avg_old = np.mean(bsaScalarData, axis=1)\n",
    "std_old = np.std(bsaScalarData, axis=1)\n",
    "\n",
    "sigma = (avg_new-avg_old) / np.sqrt(std_new**2 + std_old**2)\n",
    "\n",
    "# 3. Create a pandas DataFrame for structured output\n",
    "data = {\n",
    "    'New Run Avg': avg_new,\n",
    "    'New Run StdDev': std_new,\n",
    "    'Old Run Avg': avg_old,\n",
    "    'Old Run StdDev': std_old,\n",
    "    'Sigma Difference': sigma\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(data, index=bsaVars_newRun)\n",
    "\n",
    "# Format the output for readability (e.g., 3 decimal places)\n",
    "comparison_df = comparison_df.round(34)\n",
    "\n",
    "# 4. Print the comparison table\n",
    "print(\"Comparison of BSA Variable Statistics (New Run vs. Old Run)\\n\")\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 100000) # Use a large number like 100000\n",
    "print(comparison_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vtcav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
